{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: Ideal Times to Publish Certain News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a fast-paced 24-hour news cycle, it is crucial to publicize articles at the right time such that they can bring maximum impact to the audience before being overtaken and forgotten by the newer articles. For online media distribution, an effective measure of success can be the number of “shares” that a piece receives.\n",
    "To this end, we would like to determine if there is an optimal time period in which to publish news pieces. Our question is: Does the day of the week impact the type of news article that people are more likely to read or share? If so, what are the ideal times for different types of articles?\n",
    "The dataset we have chosen to work with is the Online News Popularity dataset from 2015. This dataset has 61 different attributes and outlines, the genre of 39797 articles, the day of the week they published, and the number of shares each garnered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘tidymodels’ was built under R version 4.0.2”\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 0.1.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom    \u001b[39m 0.7.0      \u001b[32m✔\u001b[39m \u001b[34mrecipes  \u001b[39m 0.1.13\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials    \u001b[39m 0.0.9      \u001b[32m✔\u001b[39m \u001b[34mrsample  \u001b[39m 0.0.7 \n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer    \u001b[39m 0.5.4      \u001b[32m✔\u001b[39m \u001b[34mtune     \u001b[39m 0.1.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata\u001b[39m 0.0.2      \u001b[32m✔\u001b[39m \u001b[34mworkflows\u001b[39m 0.2.0 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip  \u001b[39m 0.1.3      \u001b[32m✔\u001b[39m \u001b[34myardstick\u001b[39m 0.0.7 \n",
      "\n",
      "Warning message:\n",
      "“package ‘broom’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dials’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘infer’ was built under R version 4.0.3”\n",
      "Warning message:\n",
      "“package ‘modeldata’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘parsnip’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘recipes’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tune’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘workflows’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘yardstick’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: Can't subset columns that don't exist.\n\u001b[31m✖\u001b[39m Column `shares` doesn't exist.\n",
     "output_type": "error",
     "traceback": [
      "Error: Can't subset columns that don't exist.\n\u001b[31m✖\u001b[39m Column `shares` doesn't exist.\nTraceback:\n",
      "1. initial_split(data, prop = 0.6, strata = shares)",
      "2. tidyselect::vars_select(names(data), !!enquo(strata))",
      "3. eval_select_impl(NULL, .vars, expr(c(!!!dots)), include = .include, \n .     exclude = .exclude, strict = .strict, name_spec = unique_name_spec, \n .     uniquely_named = TRUE)",
      "4. with_subscript_errors(vars_select_eval(vars, expr, strict, data = x, \n .     name_spec = name_spec, uniquely_named = uniquely_named, allow_rename = allow_rename, \n .     type = type), type = type)",
      "5. tryCatch(instrument_base_errors(expr), vctrs_error_subscript = function(cnd) {\n .     cnd$subscript_action <- subscript_action(type)\n .     cnd$subscript_elt <- \"column\"\n .     cnd_signal(cnd)\n . })",
      "6. tryCatchList(expr, classes, parentenv, handlers)",
      "7. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "8. value[[3L]](cond)",
      "9. cnd_signal(cnd)",
      "10. rlang:::signal_abort(x)"
     ]
    }
   ],
   "source": [
    "set.seed(1234)\n",
    "publishing_split <- initial_split(data, prop = 0.6, strata = shares)\n",
    "publishing_train <- training(publishing_split)\n",
    "publishing_test <- testing(publishing_split)\n",
    "\n",
    "named_data <- publishing_train %>%\n",
    "    rename(\n",
    "        monday = weekday_is_monday,\n",
    "        tuesday = weekday_is_tuesday,\n",
    "        wednesday = weekday_is_wednesday,\n",
    "        thursday = weekday_is_thursday,\n",
    "        friday = weekday_is_friday,\n",
    "        saturday = weekday_is_saturday,\n",
    "        sunday = weekday_is_sunday,\n",
    "        lifestyle = data_channel_is_lifestyle,\n",
    "        entertainment =  data_channel_is_entertainment,\n",
    "        business = data_channel_is_bus,\n",
    "        society_and_medicine =  data_channel_is_socmed,\n",
    "        technology =  data_channel_is_tech,\n",
    "        world =  data_channel_is_world\n",
    "    )\n",
    "#It didn't work when all in one pipe, I have no idea why. This seems to work though\n",
    "tidy_data <- named_data %>%\n",
    "    pivot_longer(cols =  lifestyle : world, \n",
    "                 names_to = 'Genre', \n",
    "                 values_to = 'Genre_Present') %>%\n",
    "    pivot_longer(cols =   monday:sunday, \n",
    "                 names_to = 'Day_Of_Week', \n",
    "                 values_to = 'Day_Present') %>%\n",
    "    filter(Genre_Present == 1) %>%\n",
    "    filter(Day_Present == 1) %>%\n",
    "    mutate(abs_pos_neg_ratio = (global_rate_positive_words*avg_positive_polarity)/abs(global_rate_negative_words*avg_negative_polarity)) %>%\n",
    "    filter(global_rate_positive_words != 0 & global_rate_negative_words != 0) %>%\n",
    "    select(Genre, Day_Of_Week, shares,  abs_pos_neg_ratio)\n",
    "\n",
    "head(tidy_data)\n",
    "\n",
    "day_table <- tidy_data %>%\n",
    "    group_by(Day_Of_Week) %>%\n",
    "    summarize(total_articles=n(), avg_shares=mean(shares),abs_pos_neg_ratio = mean(abs_pos_neg_ratio) )\n",
    "day_table\n",
    "\n",
    "genre_table <- tidy_data %>%\n",
    "    group_by(Genre) %>%\n",
    "    summarize(total_articles=n(), avg_shares=mean(shares),abs_pos_neg_ratio = mean(abs_pos_neg_ratio) )\n",
    "genre_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_data <- tidy_data %>%\n",
    "    group_by(Genre, Day_Of_Week) %>%\n",
    "    summarize(n = n())\n",
    "\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "publish_plot <- publish_data %>%\n",
    "    ggplot(aes(x = Day_Of_Week, y = n, fill = Genre)) + \n",
    "    geom_bar(stat = 'identity', position = \"dodge\") +\n",
    "    xlab(\"Day of the Week\") +\n",
    "    ylab(\"Number of Articles Published\") +\n",
    "    labs(fill = \"Genre of Article\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "publish_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_data <- tidy_data %>%\n",
    "    group_by(Genre, Day_Of_Week) %>%\n",
    "    summarize(n = n())\n",
    "\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "publish_plot <- publish_data %>%\n",
    "    ggplot(aes(x = Day_Of_Week, y = n, fill = Genre)) + \n",
    "    geom_bar(stat = 'identity', position = \"dodge\") +\n",
    "    xlab(\"Day of the Week\") +\n",
    "    ylab(\"Number of Articles Published\") +\n",
    "    labs(fill = \"Genre of Article\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "publish_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_data_avg <- tidy_data %>%\n",
    "    group_by(Day_Of_Week, Genre) %>%\n",
    "    summarize(n = n(), Average_Shares_Per_Article = mean(shares)/n)\n",
    "\n",
    "head(share_data_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "share_plot <- share_data_avg %>%\n",
    "    ggplot(aes(x = Day_Of_Week, y = Average_Shares_Per_Article, fill = Genre)) + \n",
    "    geom_bar(stat = 'identity', position = \"dodge\") +\n",
    "    xlab(\"Day of the Week\") +\n",
    "    ylab(\"Average Shares Per Article\") +\n",
    "    labs(fill = \"Genre of Article\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "share_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_data_totals <- tidy_data %>%\n",
    "    group_by(Day_Of_Week, Genre) %>%\n",
    "    summarize(n = n(), shares = sum(shares))\n",
    "\n",
    "head(share_data_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "share_plot_proportion <- share_data_totals %>%\n",
    "    ggplot(aes(x = Day_Of_Week, y = shares, fill = Genre)) + \n",
    "    geom_bar(stat = 'identity', position = \"fill\") +\n",
    "    xlab(\"Day of the Week\") +\n",
    "    ylab(\"Proportion of Shares\") +\n",
    "    labs(fill = \"Genre of Article\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "share_plot_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_totals <- share_data_totals %>%\n",
    "    group_by(Day_Of_Week) %>%\n",
    "    summarize(Total_Shares = sum(shares))\n",
    "daily_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_daily_proportions <- share_data_totals %>%\n",
    "    inner_join(daily_totals) %>%\n",
    "    mutate(share_proportion = shares/Total_Shares)\n",
    "head(share_daily_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(lhs, parent, parent): object 'share_daily_proportions' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(lhs, parent, parent): object 'share_daily_proportions' not found\nTraceback:\n",
      "1. share_daily_proportions %>% ggplot(aes(x = Day_Of_Week, y = share_proportion, \n .     fill = Genre))",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)"
     ]
    }
   ],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "share_plot_proportioned <- share_daily_proportions %>%\n",
    "    ggplot(aes(x = Day_Of_Week, y = share_proportion, fill = Genre)) + \n",
    "    geom_bar(stat = 'identity', position = \"dodge\") +\n",
    "    xlab(\"Day of the Week\") +\n",
    "    ylab(\"Proportion of Daily Shares\") +\n",
    "    labs(fill = \"Genre of Article\") +\n",
    "\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "share_plot_proportioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by analyzing the dataset in its original form to determine the correct way to import it into Jupyter notebooks, and by creating a GitHub where we can share our project contributions. We will tidy the dataset to ensure that columns represent variables, rows represent observations, and cells contain single values. Next, we will use the variable ‘Day of the Week’ juxtaposed (individually) with the variables of  ‘Proportion of Shares’, ‘Proportion of Daily Shares’, ‘Average Shares per Article’, and ‘Number of Articles Published’ to create visualizations of the data (coloured bar graphs). We will study the data visualizations in order to draw information about article sharing and publishing on each day of the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Outcomes and Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are expecting to determine whether the day of the week will have an impact on the type of news article that people are more likely to read or share. The findings can be used to optimize the efficiency of when news articles should be published so that they are not overtaken and forgotten as newer topics get published. Future questions may include: How often should newspaper companies publish new articles? When is the best day of the week and time of the day to publish new articles?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
